
# Management is both nascent and outdated

Management as a discipline is simultaneously a nascent concept and grossly outdated.
This may appear contradictory, but let's look at it from the perspective of humanity overall.

## From Man to Management

Genetically, man can be traced to roughly six (6) million years ago when the ape
lineage divided into paths that would eventually lead separately to man and
to chimpanzees.
Anatomically, modern man is about 200,000 years old, beginning when the
subspecies of Homo sapiens evolved from archaic humans.
Behaviorally, modern man is closer to 40,000 years old.
Somewhere between 50,000 and 40,000 years ago, Homeo sapiens started to
exhibit behaviors of cognition, including abstract thinking, use of symbols,
and social learning.
If we can agree, for the sake of argument, that modern man is fundamentally
characterized by these capabilities, then we can set 40,000 years ago as our
starting point for humans.
30,000 years ago, humans were hunter gatherers with relatively crude instruments.
20,000 years ago, humans had clay pottery and started the use of raw materials.
In the next 10,000 years, humans made significant advancements in that we started
farming and domesticated some animals to our purpose.

*** TODO: Look at history of slave labor and use of humans as labor force on large scale ***

- 6,500 years ago, we invented the plow.
- 6,000 years ago, we invented the wheel.
- 5,400 years ago, we began writing.
- 5,200 years ago, we added sails to boats.
- 5,000 years ago, we started mass producing and using bricks.
- Palaces and cities were easier to build.
- 4,700 years ago, the first pyramids were built.
- 4,500 years ago, the first written laws were established.
- 2,800 years ago, the first olympics take place.
- 2,200 years ago, the great wall of china is constructed.
- 1,550 years ago, London is established.

In the following 7,500 years, we created the plow, the wheel and written language.
We put sails on boats, began mass production of bricks, built the pyramids
and the great wall, established cities and municipal concepts, and documented the first written laws.

***TODO: Look at history of Scientific breakthroughs - advancement of knowledge?***

Over the course of the next 2350 years, leading up to approximately 150 years ago,
dynasties


Fast forward 39,900 years from the advent of behavioral modernity, and man
conceives of the notion of "management" as a role and discipline.

It wasn't until the late 1800s, less then 150 years ago, that the title of manager
started to appear in job listings. The notion was all but non-existent prior to that.
There we no managers of clay pottery, no managers of farms, and no managers to
run the early mass production of bricks. Nobody held the title of manager
while people built the great wall or the pyramids or our early cities.

***TODO: Look at history of Bureaucracy?***

Between 1890 and 1920, the position of manager and the general responsibilities of the role
emerged from a new need brought about, in great part, by mass production and the
assembly line. For the first time in history, companies were growing well beyond
a few hundred people in size. Markets were expanding as we improved the ability to
traverse the globe. With train systems, shipping yards, and new means of powering large
vessels be they on land or in water, goods were able to be transported anywhere in the world.

*** TODO: Research more about Scientific Management / Taylorism and others ***

During this 30 year period from 1890 to 1920, men like Frederick Winslow Taylor
and ***XXXXXX***
studied how work was accomplished within shipping yards and on factory floors.
They looked for ways to improve efficiencies in order to keep up with expanding
demand while simultaneously containing costs.
The practice of studying, measuring, and monitoring work became broadly known as
Scientific Management.
Through Scientific Management, Taylor and others were able to show significant
improvements.

***TODO: Examples of improvements from scientific management***

Then, in 1921, Harvard Business School launched the first Masters in Business Administration
program, based heavily on the theories and practices found in Scientific Management.
The formal discipline of Management went mainstream.

As of this writing, in 2017:
Anatomic man is 200,000 years old.
Cognitive man is 40,000 years old.
Mass production and organized use of human labor are 5,000 years old.
Management as a discipline is 100 years old.

On a 5,000 year timeline, much less 40,000 or even 200,000, Management as a
discipline is clearly a nascent concept.

So how is it that Management is simultaneously grossly outdated?

## From Management to Now

It took man 35,000 years to go from abstract thought and social learning to the
advent of mass production. It took man another 5,000 years to go from mass production
to the formal introduction of Management. Over those 40,000 years, the evolution
of technology accelerated. From plows and wheels to sails to writing instruments,
each advancement shrunk the world and increased the rate at which knowledge could
be transferred. By the time Management was introduced, humans had printing presses,
telegraph, radio, and combustion engines. In 1921, the year Harvard introduced the
MBA program, *[stuff about computers]*.

The labor opportunities in the 1920s were primarily assembly, transport, and record keeping.
The preponderance of jobs were either assembling parts into components;
assembling components into products; moving parts, components, and
products to locations for assembly or sale; or keeping records concerning each of
these activities.

Procedures, policies, and protocols governed the work.
There was an optimal way to do each job.
This work was amenable to the Scientific Management approach of the times.
The affect of one's efforts was predictable and the efforts themselves were
measurable and could be optimized.

***Advance to Deming / Ohno***

As manufacturing became more complicated; multiple components, often hundreds
for a single product, and customization
Prediction became less accurate - variability in the system
Old measures were no longer appropriate ***(?)***
Holding employees accountable to measures outside of their control did not improve
quality
Providing employees a means of inspecting, reporting, and ameliorating errors via
mechanisms like andon cords
The need for specialization increased as employees and their analytic capability
became a more critical component of the process

***TODO: Tie these timelines together. Want to have advances in management lead to 1965.***

### Enter Moore's Law

In 1965, Gordon Moore, co-founder of Intel made what at the time may have
seemed a simple observation. He noted that the number of transistors per square
inch on integrated circuits had doubled every year since the integrated circuit
was first demonstrated by Jack Kilby of Texas Instruments in 1958.
Moore predicted that this rate of growth would continue for the
foreseeable future. A decade later, in 1975, he revised the forecast to indicate
a doubling every two years. This observation and prediction became commonly
known in the electronics and computer industry as "Moore's Law". Not an actual
physical or natural law, the name stuck none the less.

Moore's prediction held true until around 2012 when the rate fell from the
steady pace of the prior 37 years. In 2015, Brian Krzanich, CEO of Intel,
confirmed that the pace has slowed to a doubling every two and a half years.

The impact of this has been tremendous. Computing power has essentially increased
exponentially for the better of 5 decades while the relative cost has decreased
at the same fundamental rate. With power and cost as two key drivers of
technological advancement, these trends in increased power and decreased cost have not
only contributed to the explosive growth of existing technologies, but have
enabled the launch of entirely new industries as well.

Through a series of advancements, computer chips have grown more powerful and
smaller at the same time, allowing for more computing power in smaller and
smaller components.
Advancements in integration and microelectromechanical
systems have resulted in accelerometers and gyroscopes in phones and even watches.
We wear devices on our wrists that measure our steps, altitude changes, and
sleep patterns.
These devices have more computing power than the systems that sent the first
men to the moon.
And they fit on our wrists!
Science fiction is becoming science fact right before our eyes.
